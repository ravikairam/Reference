Open Anaconda prompt
To Create new env - conda create -n project1 python==3.6.9
to activate this env  - conda activate project1
to change the env - codna deactivate 
to install tensorflow - pip install tensorflow
to install jupyter notebook - pip install jupyter
python
print(tf.__version__)

create a new virtual environment

conda create -n ravi python==3.6.9
conda activate ravi
pip install tensorflow==2.3.0
pip install jupyter
import tensorflow as tf
print(tf.__version__)
python

conda env list
conda deactivate
conda env remove -n ENV_NAME

To check packages are available in our environment :
conda list

git init
============

git status
==========
git add .
===========
git commit -m "initial commit"
=============
git push repo_url master    #Remote

alternate:

git remote add origin remoteurl

git push origin master

Pycharm:

===========
No python interpreter configured for the project

1.Go to file --> settings --> click on the project --> Python Interpreter -->Gear button --> add python interpreter -->conda environment
             --> change python version to 3.6 --> click on ok
2.conda activate env_name
3.pip install -r requirements.txt # to install all packages at once

###git 
install git 

get your git repo (where your code should go to) - copy the link 
   1. click on the git repo url -> a page opens here -> top right corner  you see, clone option > click on that -> select SSH -> copy the url.

create a folder in your local > 
goto folder >
 right click, git bash >
 Enter command.,  git clone  paste the git repo url link
 Then a repo in ur local is created..
 
 
 
 Repeat for every changes and push the code into git
 
 Copy the file in the newly created local repo , example main.py > right click bit bash 
   git add .
   git commit -m "comment"
   git push
   
git@ssh.dev.azure.com's password: windows

Getting access to downlad repo from Azure devops git

1. create a folder .ssh in root dir (C:\Users\DERAKYR)
2. open windowspoershell in the root directory
 ssh-keygen -o -t rsa -C "ravi.kyram@de.abb-com"
and give enter many times till key is Generated
3. then some files created in .ssh folder
4. open id_rsa.pub in notepad and copy the key.
5. Open the git profile and go to settings:ssh public keys
6. add new key and give key name and paste key in public key data
7.click on the git repo url -> a page opens here -> top right corner  you see, clone option > click on that -> select SSH -> copy the url.

create a folder in your local > 
goto folder >
 right click, git bash >
 Enter command.,  git clone  paste the git repo url link
 Then a repo in ur local is created..
   

label = [0,0,0,1,1,2,2,3,3,4,5,5,5,5]
max(label,key=label.count)

Heroku cloud:

===========

1.Sign up for Heroku (https://heroku.com)

2.Create a new python file in the same project and name it as app.py

3.Copy the complete code from clientapp.py to app.py
(client app is development server and we do not use in production environment.)
4.Move clApp = ClientApp() line to above the function in app.py file
5. remove host information from app.py
6. pip install gunicorn
7. pip freeze > requirements.txt (It adds gunicorn installation to requirements.txt file)
8. gunicorn app:app
9. create a Procfile
   note: File name should not have any extension
   # add below lines in Procfile
   web: gunicorn app:app
7. Go to project directory through cmd
8. git init (.git folder is created in project directory)
9. git status
10.git add -A
11.git status
12.git add . (To add changes )
13.git commit -m "initial commit"
14.git status
15.heroku create
(if heroku is not found install heroku cli nad also make sure you have heroku webpage is opened with your login credentials)
16.git remote -v
17.git push heroku master
18.heroku logs --tail

souran
AWS Deployment:

===========

1. Go to https://aws.amazon.com/ and click on complete signup
2.AWS elastic beanstalk
3. The mail python file named as application.py
4.Your flask object name, which we have defined in application.py should also be the application
5.pip install gunicorn
6.pip freeze > requirements.txt (It adds gunicorn installation to requirements.txt file)
7.gunicorn application:application ( To run locally)
8..ebignore is responsible to hold the name of those files which we do not want to push to cloud
9. create a requirement.txt file.pip freeze > requirements.txt (It adds gunicorn installation to requirements.txt file)
10.create a folder called .ebextensions
11. Inside .ebextensions we need to create a python.config file
12.mention the commands in python.config
   option_settings:
     "aws:elasticbeanstalk:container:python":
       WSGIPath: application:application

After creating application using elasticbeanstalk(useful for only web-application)
EC2 works for any applications.

a. Creating environment
b. Launching s3 bucket
c. Security group is creating
d. It creates ec2 instance
e. create auto-scaling operations
f. create load balancer




GCP cloud shell

Login to cloud.google.com
Go to IAM&Admin --> Manage resources --> create Project
Install Google clous sdk 

stepi: click on activate clous shell (top right corner)
step2: once cloud shell is open click on open in editor
step3: open in terminal
step4: git clone # git project url#
step5: Get inside the project which you have cloned
       cd #project name folder#
step6: Select the project on GCP which you want to use for this cloned project
       gcloud config set #project id #
step7: gcloud app deploy
       

Azure:

